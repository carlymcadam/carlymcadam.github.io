<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.6.40">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">

<meta name="author" content="Carly McAdam">
<meta name="dcterms.date" content="2025-03-16">
<meta name="description" content="Essay: Limits of the Quantitative Approach to Bias and Fairness">

<title>Limits of the Quantitative Approach to Bias and Fairness – My Awesome CSCI 0451 Blog</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
  margin-bottom: 0em;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="../../site_libs/quarto-nav/quarto-nav.js"></script>
<script src="../../site_libs/quarto-nav/headroom.min.js"></script>
<script src="../../site_libs/clipboard/clipboard.min.js"></script>
<script src="../../site_libs/quarto-search/autocomplete.umd.js"></script>
<script src="../../site_libs/quarto-search/fuse.min.js"></script>
<script src="../../site_libs/quarto-search/quarto-search.js"></script>
<meta name="quarto:offset" content="../../">
<script src="../../site_libs/quarto-html/quarto.js"></script>
<script src="../../site_libs/quarto-html/popper.min.js"></script>
<script src="../../site_libs/quarto-html/tippy.umd.min.js"></script>
<script src="../../site_libs/quarto-html/anchor.min.js"></script>
<link href="../../site_libs/quarto-html/tippy.css" rel="stylesheet">
<link href="../../site_libs/quarto-html/quarto-syntax-highlighting-549806ee2085284f45b00abea8c6df48.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="../../site_libs/bootstrap/bootstrap.min.js"></script>
<link href="../../site_libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="../../site_libs/bootstrap/bootstrap-d061bbbaa3badd1ec91a986b0919ecb7.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">
<script id="quarto-search-options" type="application/json">{
  "location": "navbar",
  "copy-button": false,
  "collapse-after": 3,
  "panel-placement": "end",
  "type": "overlay",
  "limit": 50,
  "keyboard-shortcut": [
    "f",
    "/",
    "s"
  ],
  "show-item-context": false,
  "language": {
    "search-no-results-text": "No results",
    "search-matching-documents-text": "matching documents",
    "search-copy-link-title": "Copy link to search",
    "search-hide-matches-text": "Hide additional matches",
    "search-more-match-text": "more match in this document",
    "search-more-matches-text": "more matches in this document",
    "search-clear-button-title": "Clear",
    "search-text-placeholder": "",
    "search-detached-cancel-button-title": "Cancel",
    "search-submit-button-title": "Submit",
    "search-label": "Search"
  }
}</script>
<style>

      .quarto-title-block .quarto-title-banner h1,
      .quarto-title-block .quarto-title-banner h2,
      .quarto-title-block .quarto-title-banner h3,
      .quarto-title-block .quarto-title-banner h4,
      .quarto-title-block .quarto-title-banner h5,
      .quarto-title-block .quarto-title-banner h6
      {
        color: white;
      }

      .quarto-title-block .quarto-title-banner {
        color: white;
background-image: url(../../img/landscape.png);
background-size: cover;
      }
</style>

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

<link rel="stylesheet" href="../../styles.css">
</head>

<body class="nav-fixed fullcontent">

<div id="quarto-search-results"></div>
  <header id="quarto-header" class="headroom fixed-top quarto-banner">
    <nav class="navbar navbar-expand-lg " data-bs-theme="dark">
      <div class="navbar-container container-fluid">
      <div class="navbar-brand-container mx-auto">
    <a class="navbar-brand" href="../../index.html">
    <span class="navbar-title">My Awesome CSCI 0451 Blog</span>
    </a>
  </div>
            <div id="quarto-search" class="" title="Search"></div>
          <button class="navbar-toggler" type="button" data-bs-toggle="collapse" data-bs-target="#navbarCollapse" aria-controls="navbarCollapse" role="menu" aria-expanded="false" aria-label="Toggle navigation" onclick="if (window.quartoToggleHeadroom) { window.quartoToggleHeadroom(); }">
  <span class="navbar-toggler-icon"></span>
</button>
          <div class="collapse navbar-collapse" id="navbarCollapse">
            <ul class="navbar-nav navbar-nav-scroll ms-auto">
  <li class="nav-item">
    <a class="nav-link" href="../../about.html"> 
<span class="menu-text">About</span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://github.com/"> <i class="bi bi-github" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
  <li class="nav-item compact">
    <a class="nav-link" href="https://twitter.com"> <i class="bi bi-twitter" role="img">
</i> 
<span class="menu-text"></span></a>
  </li>  
</ul>
          </div> <!-- /navcollapse -->
            <div class="quarto-navbar-tools">
</div>
      </div> <!-- /container-fluid -->
    </nav>
</header>
<!-- content -->
<header id="title-block-header" class="quarto-title-block default page-columns page-full">
  <div class="quarto-title-banner page-columns page-full">
    <div class="quarto-title column-body">
      <h1 class="title">Limits of the Quantitative Approach to Bias and Fairness</h1>
                  <div>
        <div class="description">
          Essay: Limits of the Quantitative Approach to Bias and Fairness
        </div>
      </div>
                </div>
  </div>
    
  
  <div class="quarto-title-meta">

      <div>
      <div class="quarto-title-meta-heading">Author</div>
      <div class="quarto-title-meta-contents">
               <p>Carly McAdam </p>
            </div>
    </div>
      
      <div>
      <div class="quarto-title-meta-heading">Published</div>
      <div class="quarto-title-meta-contents">
        <p class="date">March 16, 2025</p>
      </div>
    </div>
    
      
    </div>
    
  
  </header><div id="quarto-content" class="quarto-container page-columns page-rows-contents page-layout-article page-navbar">
<!-- sidebar -->
<!-- margin-sidebar -->
    
<!-- main -->
<main class="content quarto-banner-title-block" id="quarto-document-content">





<p>In a 2022 lecture at Princeton University, associate professor of computer science Arvind Narayanan stated: “currently, quantitative methods are primarily used to justify the status quo. I would argue that they do more harm than good” (<span class="citation" data-cites="narayanan2022limits">Narayanan (<a href="#ref-narayanan2022limits" role="doc-biblioref">2022</a>)</span>). As machine learning algorithms become more prevalent in our lives, and are used to aid in high-stakes decisions like prison sentencing, credit assessment, and pricing, it’s essential that we have a way to measure bias and fairness. Narayanan believes that the quantitative methods which we currently use to assess bias and fairness in machine learning are inadequate. In this essay, I will dissect Narayanan’s position on quantitative methods in bias and fairness, discuss some of the benefits of these quantitative methods, discuss some of the limitations of these quantitative methods, and unpack my own views on these methods.</p>
<p>In Narayanan’s speech, he discusses some key limitations he believes exists in our current quantitative methods for assessing fairness and bias in machine learning. He uses the COMPAS study that we have worked with in class as an example – he was initially excited about the data that exhibited bias in the COMPAS algorithm, but after further consideration he developed 7 serious limitations of the way quantitative methods are used to study discrimination. Although Narayanan believes that we should continue to use quantitative methods, he thinks these limitations need to be addressed if these methods continue to be used:</p>
<ol type="1">
<li>What counts as evidence of discrimination is a subjective choice</li>
<li>Null hypotheses allocate the burden of proof unfairly</li>
<li>Compounding inequality is not detectable by quantitative methods</li>
<li>Snapshot datasets can hide discrimination</li>
<li>Statistical controls can mask discrimination</li>
<li>Different fairness metrics can produce conflicting results</li>
<li>Numbers are the language of policymaking, even when they are misleading</li>
</ol>
<p>We’ll unpack these different ideas along the way as we bring in some more sources to highlight both the benefits and drawbacks of using these methods. First, let’s understand some of the ways in which these quantitative methods have been effective, despite their potential limitations.</p>
<p>In <em>Fairness and Machine Learning</em>, Barocas, Hardt, and Narayanan outline 3 quantitative definitions of fairness in machine learning: independence, separation, and sufficiency (<span class="citation" data-cites="barocasFairnessMachineLearning2023">Barocas, Hardt, and Narayanan (<a href="#ref-barocasFairnessMachineLearning2023" role="doc-biblioref">2023</a>)</span>). We’ll focus on independece here, which requires the sensitive characteristic to be statistically independent of the score. In the early 2010s, Amazon created and AI tool to aid their recruiting process by scoring candidates based on their resumes that did not meet this definition of independence across genders (<span class="citation" data-cites="ReutersAmazonAIRecruiting">Dastin (<a href="#ref-ReutersAmazonAIRecruiting" role="doc-biblioref">2018</a>)</span>). If we defined <span class="math inline">\(R\)</span> as the score function and <span class="math inline">\(\hat{Y} = I\{R &gt; t\}\)</span> thresholds the score at <span class="math inline">\(t\)</span>:</p>
<p><span class="math inline">\(P\{\hat{Y} | \text{male candidate}\} \neq P\{\hat{Y} | \text{female candidate}\}\)</span></p>
<p>That is, the probability of assigning a male candidate a score over the threshold was not the same as the probability of assigning a female candidate a score over the threshold. In this case, the male candidates were more likely to be assigned a higher score. This happened because the data the model was trained on was resumes submitted to the company over a 10-year period, of which most came from men. If resumes had the word “women” in them; for example, “women’s chess club captain”, these resumes were likely to be penalized. Once Amazon identified that the independence criteria was not being met for this system, the edited the tool for gender-neutrality, and decided to use the scores generated by the tool as one part of the hiring process, but not rule out any candidates based on the AI process. This example highlights some of the benefits of using quantitative methods to assess fairness and bias in machine learning algorithms. Amazon was able to use the quantitative criteria described above to identify a problem with its algorithm, and make changes to both the algorithm itself and the context in which it was used. Even though the methods like using the independence criteria certainly have some limitations, which we will discuss next, they are still able to quickly and objectively identify a problem and prompt developers to address it. Now that we’ve seen an example of the ways in which quantitative methods can be useful, we can start to understand the drawbacks and limitations of them.</p>
<p>The ProPublica article on machine bias, which we have looked at a few times in class, which analyzed the COMPAS algorithm for bias, is a great example of some of the concerns that Narayanan raises about quantitative methods to analyze bias (<span class="citation" data-cites="ProPublicaMachineBias">Angwin et al. (<a href="#ref-ProPublicaMachineBias" role="doc-biblioref">2016</a>)</span>). Even though the algorithm had similar accuracy rates across Black and White defendants, people using the algorithm failed to consider disparities in false positive and false negative rates between these groups. Many of the issues that Narayanan raises are at play here. First, there was a difference in what the algorithm’s creators thought counted as “fair” and what ProPublica thought was “fair”. To frame this in language from <em>Fairness and Machine Learning</em>, COMPAS’s creators were looking for the fact that, if <span class="math inline">\(Y\)</span> is an indicator denoting whether or not a defendant is likely to recommit a crime and <span class="math inline">\(\hat{Y}\)</span> is an indicator denoting whether that defendant actually did recommit:</p>
<p><span class="math inline">\(P\{\hat{Y} = Y| \text{white defendant}\} = P\{\hat{Y} = Y| \text{black defendant}\}\)</span></p>
<p>That is, that the accuracy of the algorithm is the same for each racial group. In moral, this is the narrow view of equality as defined in <em>Fairness and Machine Learning</em>. But, the ProPublica authors wanted a more rigorous definition of fairness that aligns with the middle view of equality: better equality in false positive rates across racial groups. In more technical terms:</p>
<p><span class="math inline">\(P\{Y = 1, \hat{Y} = 0| \text{white defendant}\} = P\{Y = 1, \hat{Y} = 0| \text{black defendant}\}\)</span></p>
<p>For the algorithm’s creators, similar accuracy rates across racial groups counted as a fair algorithm, but ProPublica argued that the false positive rate for Black defendants was nearly twice that of white defendants – causing unfair differences in how Black defendants were treated. Second, the creators of COMPAS assumed the null hypothesis that their algorithm was fair unless proven otherwise, and their defense was that no direct racial variables were used in the model—shifting the burden of proof to critics like ProPublica. This ignores the reality that historical and structural biases are embedded in the data itself, making it unnecessary for explicit race-based discrimination to still result in biased outcomes​. Third, COMPAS methods of assessing fairness could not detect compounding inequality. They assessed individual risk without considering the structural inequalities that led to higher arrest rates among Black individuals like the fact that areas with high concentrations of Black residents are more likely to be over-policed and over-charged. The COMPAS algorithm treated past arrests and convictions as neutral indicators, failing to account for how past injustice compounds over time​. Fourth, COMPAS only used a snapshot dataset – a dataset that only considered historical arrest records, not defendants’ actual long-term outcomes. Their algorithm did not consider how a Black defendant’s false high-risk classification could lead to longer incarceration times, which might in turn reduce future employment opportunities and reinforces systemic inequality. Fifth, the COMPAS algorithm controlled for factors like criminal history, age, and gender, in order to argue that any disparities across racial groups were due to legitimate risk factors rather than systemic racism. But, these risk factors were actually shaped by systemic racism, making them a proxy for assigning different scores based on race. Sixth, similar to the first issue, using different fairness metrics, in this case predictive accuracy vs.&nbsp;false positive rates, created conflicting results about whether or not the algorithm was fair. Finally, the seventh issue showed up as COMPAS continued to be used in criminal justice decisions because its numerical outputs carried authority – judges, parole officers, and policymakers trusted the algorithm’s scores despite evidence of bias. People often feel that data is unbiased and algorithms can’t be racist, but we can some of the drawbacks of using quantitative methods do assess the fairness of the COMPAS algorithm across racial groups by applying each of Narayanan’s issues with the quantitative methods uses to assess bias in the COMPAS algorithm used.</p>
<p>Ultimately, I’d agree with Narayanan’s claim about quantitative methods for assessing bias. Although quantitative methods are important and we can use them to understand limitations of our machine learning algorithms, there are many other dimensions in algorithmic bias that need to be considered. As discussed in <em>Data Feminism</em>, power dynamics that can exacerbate bias are embedded in all aspects of data collection, analysis, and interpretation of results (<span class="citation" data-cites="datafeminism2020">D’Ignazio and Klein (<a href="#ref-datafeminism2020" role="doc-biblioref">2020</a>)</span>). Narayanan claims that the burden of proof serves to favor the status quo, and <em>Data Feminism</em> goes even further as to argue that quantitative methods are not neutral – they are shaped by and continue to hold up existing power structures. In my experience, people often view quantitative methods as unbiased, they can either be “right” or “wrong”, but when we begin to dig deeper into the systemic power imbalances that are embedded into collecting and interpreting data, even outside of machine learning algorithms, we can see that when quantitative methods are used on datasets that reflect biases in our society, the method themselves begin to reinforce these inequalities. We need to use context, history, and lived experiences in addition to quantitative methods in order to truly capture bias in these algorithms – as D’Ignazio and Klein and write, “context is queen” (<span class="citation" data-cites="datafeminism2020">D’Ignazio and Klein (<a href="#ref-datafeminism2020" role="doc-biblioref">2020</a>)</span>). This past J-term, I took a class called Questioning Technology, where we discussed algorithmic bias at length. One of the most interesting issues that we discussed, brough up in a book called <em>More Than A Glitch: Confronting Race, Gender, and Ability Bias in Tech</em> was technochauvanism, a bias that considers computational solutions to be superior to all other solutions (<span class="citation" data-cites="morethanaglitch2023">Broussard (<a href="#ref-morethanaglitch2023" role="doc-biblioref">2023</a>)</span>). I think that this issue is what lies at the center of the entire discussion around machine learning bias, the fact that people are so willing to accept technological solutions as unbiased and correct. So, like Narayanan claims, I think we can continue to use machine learning algorithms and use quantitative methods to assess their fairness. In fact, I think we <em>should</em>, in order to learn how we can improve these systems. But, we can’t come at this from a technochauvanist angle. Instead, we need to approach machine learning with skepticism, bringing our knowledge of the bias intrinsically present in our datasets to our assessment of machine learning algorithms, especially when using them to inform consequential decisions that can have immense impact on peoples’ lives.</p>




<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography" id="quarto-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" data-entry-spacing="0" role="list">
<div id="ref-ProPublicaMachineBias" class="csl-entry" role="listitem">
Angwin, Julia, Jeff Larson, Surya Mattu, and Lauren Kirchner. 2016. <span>“Machine Bias.”</span> ProPublica. <a href="https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing">https://www.propublica.org/article/machine-bias-risk-assessments-in-criminal-sentencing</a>.
</div>
<div id="ref-barocasFairnessMachineLearning2023" class="csl-entry" role="listitem">
Barocas, Solon, Moritz Hardt, and Arvind Narayanan. 2023. <em>Fairness and Machine Learning: Limitations and Opportunities</em>. <span>Cambridge, Massachusetts</span>: <span>The MIT Press</span>.
</div>
<div id="ref-morethanaglitch2023" class="csl-entry" role="listitem">
Broussard, Meredith. 2023. <em>“More Than a Glitch: Confronting Race, Gender, and Ability Bias in Tech</em>. <span>Cambridge, Massachusetts</span>: <span>The MIT Press</span>.
</div>
<div id="ref-datafeminism2020" class="csl-entry" role="listitem">
D’Ignazio, Catherine, and Lauren Klein. 2020. <em>Data Feminism</em>. <span>Cambridge, Massachusetts</span>: <span>The MIT Press</span>.
</div>
<div id="ref-ReutersAmazonAIRecruiting" class="csl-entry" role="listitem">
Dastin, Jeffrey. 2018. <span>“Amazon Scraps Secret AI Recruiting Tool That Showed Bias Against Women.”</span> Reuters. <a href="https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G">https://www.reuters.com/article/us-amazon-com-jobs-automation-insight-idUSKCN1MK08G</a>.
</div>
<div id="ref-narayanan2022limits" class="csl-entry" role="listitem">
Narayanan, Arvind. 2022. <span>“The Limits of the Quantitative Approach to Discrimination.”</span> Speech.
</div>
</div></section></div></main> <!-- /main -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const onCopySuccess = function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  }
  const getTextToCopy = function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
    text: getTextToCopy
  });
  clipboard.on('success', onCopySuccess);
  if (window.document.getElementById('quarto-embedded-source-code-modal')) {
    const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
      text: getTextToCopy,
      container: window.document.getElementById('quarto-embedded-source-code-modal')
    });
    clipboardModal.on('success', onCopySuccess);
  }
    var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
    var mailtoRegex = new RegExp(/^mailto:/);
      var filterRegex = new RegExp('/' + window.location.host + '/');
    var isInternal = (href) => {
        return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
    }
    // Inspect non-navigation links and adorn them if external
 	var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
    for (var i=0; i<links.length; i++) {
      const link = links[i];
      if (!isInternal(link.href)) {
        // undo the damage that might have been done by quarto-nav.js in the case of
        // links that we want to consider external
        if (link.dataset.originalHref !== undefined) {
          link.href = link.dataset.originalHref;
        }
      }
    }
  function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
    const config = {
      allowHTML: true,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start',
    };
    if (contentFn) {
      config.content = contentFn;
    }
    if (onTriggerFn) {
      config.onTrigger = onTriggerFn;
    }
    if (onUntriggerFn) {
      config.onUntrigger = onUntriggerFn;
    }
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      if (note) {
        return note.innerHTML;
      } else {
        return "";
      }
    });
  }
  const xrefs = window.document.querySelectorAll('a.quarto-xref');
  const processXRef = (id, note) => {
    // Strip column container classes
    const stripColumnClz = (el) => {
      el.classList.remove("page-full", "page-columns");
      if (el.children) {
        for (const child of el.children) {
          stripColumnClz(child);
        }
      }
    }
    stripColumnClz(note)
    if (id === null || id.startsWith('sec-')) {
      // Special case sections, only their first couple elements
      const container = document.createElement("div");
      if (note.children && note.children.length > 2) {
        container.appendChild(note.children[0].cloneNode(true));
        for (let i = 1; i < note.children.length; i++) {
          const child = note.children[i];
          if (child.tagName === "P" && child.innerText === "") {
            continue;
          } else {
            container.appendChild(child.cloneNode(true));
            break;
          }
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(container);
        }
        return container.innerHTML
      } else {
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        return note.innerHTML;
      }
    } else {
      // Remove any anchor links if they are present
      const anchorLink = note.querySelector('a.anchorjs-link');
      if (anchorLink) {
        anchorLink.remove();
      }
      if (window.Quarto?.typesetMath) {
        window.Quarto.typesetMath(note);
      }
      if (note.classList.contains("callout")) {
        return note.outerHTML;
      } else {
        return note.innerHTML;
      }
    }
  }
  for (var i=0; i<xrefs.length; i++) {
    const xref = xrefs[i];
    tippyHover(xref, undefined, function(instance) {
      instance.disable();
      let url = xref.getAttribute('href');
      let hash = undefined; 
      if (url.startsWith('#')) {
        hash = url;
      } else {
        try { hash = new URL(url).hash; } catch {}
      }
      if (hash) {
        const id = hash.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note !== null) {
          try {
            const html = processXRef(id, note.cloneNode(true));
            instance.setContent(html);
          } finally {
            instance.enable();
            instance.show();
          }
        } else {
          // See if we can fetch this
          fetch(url.split('#')[0])
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.getElementById(id);
            if (note !== null) {
              const html = processXRef(id, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      } else {
        // See if we can fetch a full url (with no hash to target)
        // This is a special case and we should probably do some content thinning / targeting
        fetch(url)
        .then(res => res.text())
        .then(html => {
          const parser = new DOMParser();
          const htmlDoc = parser.parseFromString(html, "text/html");
          const note = htmlDoc.querySelector('main.content');
          if (note !== null) {
            // This should only happen for chapter cross references
            // (since there is no id in the URL)
            // remove the first header
            if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
              note.children[0].remove();
            }
            const html = processXRef(null, note);
            instance.setContent(html);
          } 
        }).finally(() => {
          instance.enable();
          instance.show();
        });
      }
    }, function(instance) {
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            div.style.left = 0;
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
        // Handle positioning of the toggle
    window.addEventListener(
      "resize",
      throttle(() => {
        elRect = undefined;
        if (selectedAnnoteEl) {
          selectCodeLines(selectedAnnoteEl);
        }
      }, 10)
    );
    function throttle(fn, ms) {
    let throttle = false;
    let timer;
      return (...args) => {
        if(!throttle) { // first call gets through
            fn.apply(this, args);
            throttle = true;
        } else { // all the others get throttled
            if(timer) clearTimeout(timer); // cancel #2
            timer = setTimeout(() => {
              fn.apply(this, args);
              timer = throttle = false;
            }, ms);
        }
      };
    }
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->




</body></html>